{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6aa93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from neo4j import GraphDatabase\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_community.chains.graph_qa.cypher import GraphCypherQAChain\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_community.graphs import Neo4jGraph as LangChainNeo4jGraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5338fb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\")\n",
    "NEO4J_URI = os.getenv(\"NEO4J_URI\")\n",
    "NEO4J_USERNAME = os.getenv(\"NEO4J_USERNAME\")\n",
    "NEO4J_DATABASE = os.getenv(\"NEO4J_DATABASE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b9244028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing GraphRAG chain-\n",
      "Chain Initialized\n",
      " failed to initialize the application : 'module' object is not callable\n"
     ]
    }
   ],
   "source": [
    "# MAIN\n",
    "def create_graph_rag_chain():\n",
    "    # creating the main QA chaint that connect to Neo4j and uses and LLM\n",
    "    \n",
    "    if not GROQ_API_KEY or not NEO4J_PASSWORD:\n",
    "        raise ValueError(\"API key or password not found\")\n",
    "    \n",
    "    # Initialize connection to Neo4j\n",
    "    graph = LangChainNeo4jGraph(\n",
    "        url = NEO4J_URI,\n",
    "        username = NEO4J_USERNAME,\n",
    "        password = NEO4J_PASSWORD,\n",
    "        database = NEO4J_DATABASE\n",
    "    )\n",
    "\n",
    "    # refreshing the schema to make sure that LLM has lastest graph structure\n",
    "    graph.refresh_schema()\n",
    "\n",
    "    # Initialize the LLM\n",
    "    llm = ChatGroq(temperature=0, model = \"meta-llama/llama-4-maverick-17b-128e-instruct\" )\n",
    "\n",
    "    # Creating GraphCypherQAChain\n",
    "    # It will take a question, generate Cypher query, execute it\n",
    "    # andthen use the result to answer the orignal question\n",
    "    chain = GraphCypherQAChain.from_llm(\n",
    "        cypher_llm = llm,\n",
    "        qa_llm = llm,\n",
    "        graph = graph,\n",
    "        verbose = True, # true to see the generated cypher queries\n",
    "        return_intermediate_steps = True, # helps in debugging\n",
    "        allow_dangerous_requests=True # Acknowledges the security risk of LLM-generated queries\n",
    "    )\n",
    "    return chain\n",
    "\n",
    "def query_graph(question, history):\n",
    "    # function to be called by gradio interface. It takes a user questoin\n",
    "    # queries the knowledge graph and returns the answer\n",
    "\n",
    "    try:\n",
    "        #geenrate a response using the GraphRAG Chain\n",
    "        result = rag_chain.inovke({\"query\": question})\n",
    "\n",
    "        #extract the final answer and the intermediate cypher query for dispaly\n",
    "        answer = result[\"result\"]\n",
    "        intermediate_steps = result[\"intermediate_steps\"]\n",
    "        cypher_query = \"\"\n",
    "        if intermediate_steps and len(intermediate_steps) > 0:\n",
    "            cypher_query = intermediate_steps[0].get(\"query\", \"could not generate cypher query\")\n",
    "\n",
    "        \n",
    "        # format the output for the UI\n",
    "        formatted_output = (\n",
    "            f\"**Answer:**\\n{answer}\\n\\n\"\n",
    "            f\"--- \\n\"\n",
    "            f\"**Generated Cypher Query:**\\n```cypher\\n{cypher_query}\\n```\"\n",
    "\n",
    "        )\n",
    "        return formatted_output\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error during query: {e}\")\n",
    "        return f\"An error occured: {e}\"\n",
    "    \n",
    "\n",
    "# Gradio Interface\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Initializing GraphRAG chain-\")\n",
    "    try:\n",
    "        rag_chain = create_graph_rag_chain()\n",
    "        print(\"Chain Initialized\")\n",
    "\n",
    "        # Setup  the Gradio Interface\n",
    "        with gr.blocks(theme=gr.themes.Soft(), title=\"Cancer Monograph GraphRAG\") as demo:\n",
    "            gr.Markdown(\n",
    "                 \"\"\"\n",
    "                 Ask a question about the ICMR Cancer Monograph, and the system will query the knowledge graph to find the answer\n",
    "                 **Example:**\n",
    "                 - What are the leading sites of cancer in Mumbai?\n",
    "                 - Which risk factors are associated with Breast Cancer?\n",
    "                \"\"\"\n",
    "            )\n",
    "            gr.chat_interface(\n",
    "                fn=query_graph,\n",
    "                title=\"ask the monograph\",\n",
    "                chatbot=gr.Chatbot(height=500),\n",
    "                textbox=gr.Textbox(placeholder=\"e.g., what is the role of tobacco in oral cancer?\", container=False, Scale=7),\n",
    "                examples=[\n",
    "                    \"What are the leading sites of cancer in Mizoram?\",\n",
    "                    \"Which studies did the ICMR conduct on tobacco?\",\n",
    "                    \"What is the link between the GSTM1 gene and oral cancer?\"\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        \n",
    "        print(\"\\nLaunching Gradio App, open the URL\")\n",
    "        demo.launch(share=True) # share = true, creates a public link\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\" failed to initialize the application : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90f8909",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
